{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNYQeZ1hK4QxTQqsIBlaJiU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JavokhirJambulov/AIapplicationSystem/blob/main/12204567_Homework_Week_5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Activity 1:"
      ],
      "metadata": {
        "id": "78bURJFMWsFh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SBddKOym9H-2",
        "outputId": "ff466c0e-8b2f-4169-a12d-165fa396fd23"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "# Import TensorFlow and other libraries\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "# Load the MNIST dataset\n",
        "mnist = tf.keras.datasets.mnist\n",
        "# Split the dataset into training and test sets\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "# Normalize the images\n",
        "train_images = train_images / 255.0\n",
        "test_images = test_images/255.0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to create and evaluate model with different activation functions\n",
        "def evaluate_activation (activation_function):\n",
        "  model = tf.keras. Sequential ([\n",
        "    tf.keras.layers.Flatten (input_shape=(28, 28)),\n",
        "    tf.keras.layers.Dense (128, activation=activation_function),\n",
        "    tf.keras.layers.Dense (10, activation='softmax')\n",
        "  ])\n",
        "  model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "  model.fit(train_images, train_labels, epochs=5)\n",
        "  test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "  print(f\"Test accuracy with {activation_function}: {test_acc}\")\n",
        "# Evaluate models with different activation functions\n",
        "for activation in ['sigmoid', 'tanh', 'relu']:\n",
        "  evaluate_activation (activation)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xMDh5_dvCRqd",
        "outputId": "c5fc750c-1137-4edb-c14f-287267aacfc0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3951 - accuracy: 0.8980\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1912 - accuracy: 0.9452\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1401 - accuracy: 0.9595\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 0.1091 - accuracy: 0.9689\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0880 - accuracy: 0.9751\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.1030 - accuracy: 0.9682\n",
            "Test accuracy with sigmoid: 0.9682000279426575\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 0.2814 - accuracy: 0.9186\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1368 - accuracy: 0.9602\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0932 - accuracy: 0.9729\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0681 - accuracy: 0.9798\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0511 - accuracy: 0.9857\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0722 - accuracy: 0.9775\n",
            "Test accuracy with tanh: 0.9775000214576721\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2621 - accuracy: 0.9256\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1180 - accuracy: 0.9652\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0804 - accuracy: 0.9756\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0606 - accuracy: 0.9818\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0465 - accuracy: 0.9852\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0846 - accuracy: 0.9734\n",
            "Test accuracy with relu: 0.9733999967575073\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Activity 1:\n",
        "\n",
        "*  Accuracy with sigmoid: 0.9682000279426575\n",
        "\n",
        "*  Accuracy with tanh:    0.9775000214576721\n",
        "\n",
        "*  Acuracy with relu:     0.9733999967575073\n",
        "\n"
      ],
      "metadata": {
        "id": "GFBEpkOYEKNk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Activity 2:"
      ],
      "metadata": {
        "id": "b59SjHvNNsKp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate models with different learning rates\n",
        "for Ir in [0.001, 0.01, 0.1]:\n",
        "  optimizer = tf.keras.optimizers.Adam(learning_rate=Ir)\n",
        "  model = tf.keras. Sequential ([\n",
        "  tf.keras.layers. Flatten (input_shape=(28, 28)),\n",
        "  tf.keras. layers. Dense (128, activation= 'relu'),\n",
        "  tf.keras. layers. Dense (10, activation='softmax')\n",
        "  ])\n",
        "  model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "  model.fit(train_images, train_labels, epochs=5, batch_size=32)\n",
        "  test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "  print(f\"Test accuracy with learning rate {Ir}: {test_acc}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ucudOBREgD0",
        "outputId": "6a1686cf-709b-43cf-a9e6-2b11cdd1e8f7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2573 - accuracy: 0.9267\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1125 - accuracy: 0.9664\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0777 - accuracy: 0.9766\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0585 - accuracy: 0.9820\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0449 - accuracy: 0.9864\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0720 - accuracy: 0.9785\n",
            "Test accuracy with learning rate 0.001: 0.9785000085830688\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2430 - accuracy: 0.9283\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1553 - accuracy: 0.9564\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1447 - accuracy: 0.9615\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1288 - accuracy: 0.9650\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1246 - accuracy: 0.9677\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.1427 - accuracy: 0.9657\n",
            "Test accuracy with learning rate 0.01: 0.9656999707221985\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 1.1451 - accuracy: 0.6788\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 1.2898 - accuracy: 0.5989\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 1.3296 - accuracy: 0.5545\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 1.2966 - accuracy: 0.5814\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 1.2634 - accuracy: 0.6043\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 1.4489 - accuracy: 0.5285\n",
            "Test accuracy with learning rate 0.1: 0.5285000205039978\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate models with different learning rates\n",
        "for Ir in [0.001, 0.01, 0.1]:\n",
        "  optimizer = tf.keras.optimizers.Adam(learning_rate=Ir)\n",
        "  model = tf.keras. Sequential ([\n",
        "  tf.keras.layers. Flatten (input_shape=(28, 28)),\n",
        "  tf.keras. layers. Dense (128, activation= 'relu'),\n",
        "  tf.keras. layers. Dense (10, activation='softmax')\n",
        "  ])\n",
        "  model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "  model.fit(train_images, train_labels, epochs=5, batch_size=64)\n",
        "  test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "  print(f\"Test accuracy with learning rate {Ir}: {test_acc}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w4Q_mRegGOSM",
        "outputId": "a7b23f44-ef47-4d3b-b6c0-49a077881542"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "938/938 [==============================] - 3s 3ms/step - loss: 0.2939 - accuracy: 0.9173\n",
            "Epoch 2/5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.1319 - accuracy: 0.9617\n",
            "Epoch 3/5\n",
            "938/938 [==============================] - 3s 3ms/step - loss: 0.0934 - accuracy: 0.9730\n",
            "Epoch 4/5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0722 - accuracy: 0.9786\n",
            "Epoch 5/5\n",
            "938/938 [==============================] - 3s 3ms/step - loss: 0.0568 - accuracy: 0.9829\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0779 - accuracy: 0.9774\n",
            "Test accuracy with learning rate 0.001: 0.977400004863739\n",
            "Epoch 1/5\n",
            "938/938 [==============================] - 3s 3ms/step - loss: 0.2181 - accuracy: 0.9341\n",
            "Epoch 2/5\n",
            "938/938 [==============================] - 3s 3ms/step - loss: 0.1298 - accuracy: 0.9628\n",
            "Epoch 3/5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.1125 - accuracy: 0.9674\n",
            "Epoch 4/5\n",
            "938/938 [==============================] - 3s 3ms/step - loss: 0.1028 - accuracy: 0.9711\n",
            "Epoch 5/5\n",
            "938/938 [==============================] - 3s 3ms/step - loss: 0.0929 - accuracy: 0.9734\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.1863 - accuracy: 0.9552\n",
            "Test accuracy with learning rate 0.01: 0.9552000164985657\n",
            "Epoch 1/5\n",
            "938/938 [==============================] - 3s 3ms/step - loss: 0.9054 - accuracy: 0.7910\n",
            "Epoch 2/5\n",
            "938/938 [==============================] - 3s 3ms/step - loss: 0.8145 - accuracy: 0.7702\n",
            "Epoch 3/5\n",
            "938/938 [==============================] - 3s 3ms/step - loss: 0.8705 - accuracy: 0.7626\n",
            "Epoch 4/5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.9146 - accuracy: 0.7546\n",
            "Epoch 5/5\n",
            "938/938 [==============================] - 3s 3ms/step - loss: 0.9291 - accuracy: 0.7477\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 1.2977 - accuracy: 0.7064\n",
            "Test accuracy with learning rate 0.1: 0.7063999772071838\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate models with different learning rates\n",
        "for Ir in [0.001, 0.01, 0.1]:\n",
        "  optimizer = tf.keras.optimizers.Adam(learning_rate=Ir)\n",
        "  model = tf.keras. Sequential ([\n",
        "  tf.keras.layers. Flatten (input_shape=(28, 28)),\n",
        "  tf.keras. layers. Dense (128, activation= 'relu'),\n",
        "  tf.keras. layers. Dense (10, activation='softmax')\n",
        "  ])\n",
        "  model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "  model.fit(train_images, train_labels, epochs=5, batch_size=128)\n",
        "  test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "  print(f\"Test accuracy with learning rate {Ir}: {test_acc}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BQ0JMk7eGcLs",
        "outputId": "dc3336d7-4c8f-40b2-ef05-7bff49929b20"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 0.3566 - accuracy: 0.9019\n",
            "Epoch 2/5\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1632 - accuracy: 0.9537\n",
            "Epoch 3/5\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1175 - accuracy: 0.9667\n",
            "Epoch 4/5\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0910 - accuracy: 0.9742\n",
            "Epoch 5/5\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0735 - accuracy: 0.9789\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0872 - accuracy: 0.9737\n",
            "Test accuracy with learning rate 0.001: 0.9736999869346619\n",
            "Epoch 1/5\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 0.2196 - accuracy: 0.9330\n",
            "Epoch 2/5\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.1080 - accuracy: 0.9671\n",
            "Epoch 3/5\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0877 - accuracy: 0.9735\n",
            "Epoch 4/5\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0745 - accuracy: 0.9776\n",
            "Epoch 5/5\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0640 - accuracy: 0.9805\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.1451 - accuracy: 0.9643\n",
            "Test accuracy with learning rate 0.01: 0.9642999768257141\n",
            "Epoch 1/5\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.8617 - accuracy: 0.8338\n",
            "Epoch 2/5\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.5446 - accuracy: 0.8683\n",
            "Epoch 3/5\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.5129 - accuracy: 0.8752\n",
            "Epoch 4/5\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.5348 - accuracy: 0.8697\n",
            "Epoch 5/5\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.5606 - accuracy: 0.8636\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.6884 - accuracy: 0.8716\n",
            "Test accuracy with learning rate 0.1: 0.8715999722480774\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Activity 2:\n",
        "\n",
        "Batch size: 32 and different learning rates(0.001, 0.01, 0.1)\n",
        "\n",
        "Test accuracy with learning rate 0.001: 0.9785000085830688\n",
        "\n",
        "Test accuracy with learning rate 0.01: 0.9656999707221985\n",
        "\n",
        "Test accuracy with learning rate 0.1: 0.5285000205039978\n",
        "\n",
        "-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-\n",
        "\n",
        "Batch size: 64 and different learning rates(0.001, 0.01, 0.1)\n",
        "\n",
        "Test accuracy with learning rate 0.001: 0.977400004863739\n",
        "\n",
        "Test accuracy with learning rate 0.01: 0.9552000164985657\n",
        "\n",
        "Test accuracy with learning rate 0.1: 0.7063999772071838\n",
        "\n",
        "\n",
        "-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-\n",
        "\n",
        "Batch size: 128 and different learning rates(0.001, 0.01, 0.1)\n",
        "\n",
        "Test accuracy with learning rate 0.001: 0.9736999869346619\n",
        "\n",
        "Test accuracy with learning rate 0.01: 0.9642999768257141\n",
        "\n",
        "Test accuracy with learning rate 0.1: 0.8715999722480774"
      ],
      "metadata": {
        "id": "ytHThF4fI7iC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Activity 3:"
      ],
      "metadata": {
        "id": "kGSuKinjNl7J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the MNIST dataset\n",
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "# Split the dataset into training and test sets\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "# Normalize the images\n",
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0\n",
        "\n",
        "# Function to create and evaluate model with different activation functions and dropout\n",
        "def evaluate_activation_with_dropout(activation_function, dropout_rate=0.2):\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "        tf.keras.layers.Dense(128, activation=activation_function),\n",
        "        tf.keras.layers.Dropout(rate=dropout_rate),  # Add a dropout layer\n",
        "        tf.keras.layers.Dense(10, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    model.fit(train_images, train_labels, epochs=5)\n",
        "    test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "    print(f\"Test accuracy with {activation_function} and dropout: {test_acc}\")\n",
        "\n",
        "# Evaluate models with different activation functions and dropout rates\n",
        "for activation in ['sigmoid', 'tanh', 'relu']:\n",
        "    evaluate_activation_with_dropout(activation)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TLiIIeqhJYvh",
        "outputId": "56d27d79-9a71-4968-c68b-01b12a6e5878"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.4432 - accuracy: 0.8785\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.2308 - accuracy: 0.9329\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 13s 7ms/step - loss: 0.1747 - accuracy: 0.9487\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1409 - accuracy: 0.9582\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1195 - accuracy: 0.9650\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.1016 - accuracy: 0.9707\n",
            "Test accuracy with sigmoid and dropout: 0.9707000255584717\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3245 - accuracy: 0.9062\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1858 - accuracy: 0.9453\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1444 - accuracy: 0.9554\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1224 - accuracy: 0.9618\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1061 - accuracy: 0.9671\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0885 - accuracy: 0.9726\n",
            "Test accuracy with tanh and dropout: 0.972599983215332\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2935 - accuracy: 0.9142\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1438 - accuracy: 0.9573\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1104 - accuracy: 0.9664\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0888 - accuracy: 0.9726\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0763 - accuracy: 0.9756\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0742 - accuracy: 0.9779\n",
            "Test accuracy with relu and dropout: 0.9779000282287598\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the MNIST dataset\n",
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "# Split the dataset into training and test sets\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "# Normalize the images\n",
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0\n",
        "\n",
        "# Function to create and evaluate regularized model with different activation functions\n",
        "def evaluate_activation_with_regularization(activation_function, l2_regularization=0.01):\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "        tf.keras.layers.Dense(128, activation=activation_function,\n",
        "                              kernel_regularizer=tf.keras.regularizers.l2(l2_regularization)),  # Add L2 regularization\n",
        "        tf.keras.layers.Dense(10, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    model.fit(train_images, train_labels, epochs=5)\n",
        "    test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "    print(f\"Test accuracy with {activation_function} and L2 regularization: {test_acc}\")\n",
        "\n",
        "# Evaluate models with different activation functions and L2 regularization strengths\n",
        "for activation in ['sigmoid', 'tanh', 'relu']:\n",
        "    evaluate_activation_with_regularization(activation, l2_regularization=0.01)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BUowNiCCN3Sv",
        "outputId": "c4ae1846-4371-4ea4-ebac-0d0929390108"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.9792 - accuracy: 0.8538\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.6699 - accuracy: 0.8809\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.6088 - accuracy: 0.8827\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.5764 - accuracy: 0.8853\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 0.5555 - accuracy: 0.8874\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.5291 - accuracy: 0.8959\n",
            "Test accuracy with sigmoid and L2 regularization: 0.8959000110626221\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.6327 - accuracy: 0.8837\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.4679 - accuracy: 0.9015\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.4421 - accuracy: 0.9083\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.4182 - accuracy: 0.9165\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.4058 - accuracy: 0.9198\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.3872 - accuracy: 0.9224\n",
            "Test accuracy with tanh and L2 regularization: 0.9223999977111816\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 0.6131 - accuracy: 0.8999\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3990 - accuracy: 0.9290\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 0.3587 - accuracy: 0.9373\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3357 - accuracy: 0.9414\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3200 - accuracy: 0.9453\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.2923 - accuracy: 0.9532\n",
            "Test accuracy with relu and L2 regularization: 0.9531999826431274\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Activity 3:\n",
        "\n",
        "Baseline model:\n",
        "\n",
        "Accuracy with sigmoid: 0.9682000279426575\n",
        "\n",
        "Accuracy with tanh: 0.9775000214576721\n",
        "\n",
        "Acuracy with relu: 0.9733999967575073\n",
        "\n",
        "-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-\n",
        "\n",
        "Model with dropout layer:\n",
        "\n",
        "Test accuracy with sigmoid and dropout: 0.9707000255584717\n",
        "\n",
        "Test accuracy with tanh and dropout: 0.972599983215332\n",
        "\n",
        "Test accuracy with relu and dropout: 0.9779000282287598\n",
        "\n",
        "You can add a dropout layer by including tf.keras.layers.Dropout in your model definition. The code that was used added a dropout layer with a dropout rate of 0.2 to the model.\n",
        "\n",
        "-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-\n",
        "\n",
        "Model with L2 regularization:\n",
        "\n",
        "Test accuracy with sigmoid and L2 regularization: 0.8959000110626221\n",
        "\n",
        "Test accuracy with tanh and L2 regularization: 0.9223999977111816\n",
        "\n",
        "Test accuracy with relu and L2 regularization: 0.9531999826431274\n",
        "\n",
        "You can add L2 regularization to dense layers using the kernel_regularizer argument in the tf.keras.layers.Dense layer. The code that was used added a L2 regularization with a strength of 0.01 to the dense layers."
      ],
      "metadata": {
        "id": "7_WQDke0PE-A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Activity 4:"
      ],
      "metadata": {
        "id": "lOM86P2kQnsf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "# Assuming you have a model that has already been trained\n",
        "# Make predictions on the test dataset\n",
        "predicted_labels = model.predict(test_images)\n",
        "\n",
        "# Assuming that you have ground truth labels for the test dataset\n",
        "# Convert predicted probabilities to class labels\n",
        "predicted_classes = np.argmax(predicted_labels, axis=1)\n",
        "\n",
        "# Calculate precision, recall, and F1-score using TensorFlow\n",
        "precision = tf.keras.metrics.Precision()(test_labels, predicted_classes)\n",
        "recall = tf.keras.metrics.Recall()(test_labels, predicted_classes)\n",
        "f1 = 2 * (precision * recall) / (precision + recall)\n",
        "\n",
        "print(f\"Precision: {precision.numpy()}\")\n",
        "print(f\"Recall: {recall.numpy()}\")\n",
        "print(f\"F1-score: {f1.numpy()}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0DKvJBh6QmpA",
        "outputId": "6d3ebcb4-5847-4131-82bb-ee9f329cbb98"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 3ms/step\n",
            "Precision: 0.9934864044189453\n",
            "Recall: 0.9976718425750732\n",
            "F1-score: 0.9955747127532959\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Activity 4:\n",
        "\n",
        "Precision: 0.9934864044189453\n",
        "Precision is the metric to use when minimizing false positives is crucial.\n",
        "\n",
        "Recall: 0.9976718425750732\n",
        "Recall is the metric to use when minimizing false negatives is critical.\n",
        "\n",
        "F1-score: 0.9955747127532959\n",
        "The F1-score is the harmonic mean of precision and recall."
      ],
      "metadata": {
        "id": "hzY9szf8JHTJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Activity 5:"
      ],
      "metadata": {
        "id": "OOl1PGBWQ0zo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Load the MNIST dataset\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "# Normalize the images\n",
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0\n",
        "\n",
        "# Build the baseline feedforward neural network model\n",
        "baseline_model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=(28, 28)),  # Flatten the 28x28 input images\n",
        "    tf.keras.layers.Dense(128, activation='relu'),  # Fully connected layer with ReLU activation\n",
        "    tf.keras.layers.Dense(64, activation='relu'),   # Additional fully connected layer\n",
        "    tf.keras.layers.Dense(10, activation='softmax') # Output layer with 10 classes (digits)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "baseline_model.compile(optimizer='adam',\n",
        "                       loss='sparse_categorical_crossentropy',\n",
        "                       metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "baseline_model.fit(train_images, train_labels, epochs=5, verbose=2)\n",
        "\n",
        "# Evaluate the model on the test dataset\n",
        "test_loss, test_accuracy = baseline_model.evaluate(test_images, test_labels)\n",
        "print(f\"Test accuracy of baseline model: {test_accuracy}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zv15FF9SQ343",
        "outputId": "64dbe27e-3e97-448e-de52-db4621e8cb9b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 - 6s - loss: 0.2375 - accuracy: 0.9295 - 6s/epoch - 3ms/step\n",
            "Epoch 2/5\n",
            "1875/1875 - 6s - loss: 0.0997 - accuracy: 0.9696 - 6s/epoch - 3ms/step\n",
            "Epoch 3/5\n",
            "1875/1875 - 5s - loss: 0.0708 - accuracy: 0.9774 - 5s/epoch - 3ms/step\n",
            "Epoch 4/5\n",
            "1875/1875 - 7s - loss: 0.0535 - accuracy: 0.9830 - 7s/epoch - 4ms/step\n",
            "Epoch 5/5\n",
            "1875/1875 - 5s - loss: 0.0414 - accuracy: 0.9861 - 5s/epoch - 3ms/step\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0830 - accuracy: 0.9757\n",
            "Test accuracy of baseline model: 0.9757000207901001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
        "model_cnn = models.Sequential([\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model_cnn.compile(optimizer='adam',\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "train_images = train_images.reshape(train_images.shape[0], 28, 28, 1)\n",
        "test_images = test_images.reshape(test_images.shape[0], 28, 28, 1)\n",
        "model_cnn.fit(train_images, train_labels, epochs=5)\n",
        "test_loss, test_acc = model_cnn.evaluate(test_images, test_labels)\n",
        "print(f\"Test accuracy of CNN model: {test_acc}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hZGjmu75Vjpm",
        "outputId": "5773e6b5-013b-42e8-da34-65c466ee0b2b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 35s 18ms/step - loss: 0.1511 - accuracy: 0.9556\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 34s 18ms/step - loss: 0.0531 - accuracy: 0.9834\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 34s 18ms/step - loss: 0.0341 - accuracy: 0.9894\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 34s 18ms/step - loss: 0.0224 - accuracy: 0.9930\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 34s 18ms/step - loss: 0.0156 - accuracy: 0.9950\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0538 - accuracy: 0.9833\n",
            "Test accuracy of CNN model: 0.983299970626831\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Activity 5:\n",
        "\n",
        "Test accuracy of baseline model: 0.9757000207901001\n",
        "\n",
        "Test accuracy of CNN model: 0.983299970626831\n",
        "\n",
        "CNNs are typically used for image-related tasks and often outperform feedforward networks for image classification tasks like MNIST."
      ],
      "metadata": {
        "id": "tcfRwIwWQ4UH"
      }
    }
  ]
}